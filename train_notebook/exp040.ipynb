{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f536f0fe-9e06-4b17-93f1-d46b5cdb7cc3",
   "metadata": {},
   "source": [
    "- -> exp037\n",
    "- transformer Ë©¶„Åô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b524a15c-5f93-4dce-b79f-1be405036326",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7174264-b9fd-41b5-91fe-f5174dd30852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "is_kaggle_notebook = os.path.exists(\"/kaggle/input\")\n",
    "\n",
    "# ÂøÖË¶Å„Éë„ÉÉ„Ç±„Éº„Ç∏„Çí„Ç§„É≥„Çπ„Éà„Éº„É´\n",
    "if is_kaggle_notebook:\n",
    "    !pip install /kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl\n",
    "    !pip install /kaggle/input/torch-geometric-2-6-1/torch_geometric-2.6.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f929c2-afe2-4fcb-986b-6f50075faa7a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import wandb\n",
    "from rdkit import rdBase\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GroupKFold, KFold\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "rdBase.DisableLog(\"rdApp.warning\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de6f94aa-f4e5-4b14-8bad-f9f73cd60375",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "pr_number = 1\n",
    "debug = True\n",
    "augmented_feature = '[\"morgan\", \"maccs\"]'\n",
    "graph_pooling = \"mean\"\n",
    "notes = \"\"\n",
    "is_trimmer_cyclic = False\n",
    "exp = \"exp040\"\n",
    "batch_size = 256\n",
    "num_epochs = 1000\n",
    "drop_ratio = 0.5\n",
    "set_seed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7fc1016-c533-4ccb-ac2a-4947956bb60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_seed:\n",
    "    SEED = 42\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(SEED)\n",
    "\n",
    "    # # Ê±∫ÂÆöË´ñ„É¢„Éº„Éâ\n",
    "    # torch.use_deterministic_algorithms(True)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.benchmark = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ccadd16-5880-496e-a632-4d5940b2266c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mko_ya346\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "if is_kaggle_notebook:\n",
    "    module_path = f\"/kaggle/input/myproject-pr-{pr_number:04}\"\n",
    "    !mkdir src\n",
    "    !cp -r $module_path/* src/\n",
    "    src_path = \"./\"\n",
    "else:\n",
    "    src_path = \"../\"\n",
    "\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from src.data import add_descriptors, add_external_data, load_data, make_smile_canonical, generate_trimer\n",
    "from src.model import get_model\n",
    "from src.utils import NULL_FOR_SUBMISSION, generate_scaffold, score, add_scaffold_kfold, scaffold_cv_split\n",
    "from src.utils.upload_kaggle_dataset import (\n",
    "    create_kaggle_dataset_metadata,\n",
    "    upload_kaggle_dataset,\n",
    ")\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ef59d0f-f03f-4636-9839-c8cbc2b4cfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "model_names = [\n",
    "    # \"gnn\",\n",
    "    # \"bfgnn\", \"dir\", \"grin\", \"irm\", \"lstm\", \"rpgnn\", \n",
    "    \"smiles_transformer\", \n",
    "    # \"ssr\"\n",
    "]\n",
    "config = {\n",
    "    \"debug\": debug,\n",
    "    \"n_splits\": 5,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"drop_ratio\": drop_ratio,\n",
    "    \"graph_pooling\": graph_pooling,\n",
    "    \"is_trimmer_cyclic\": is_trimmer_cyclic,\n",
    "}\n",
    "smiles_col = \"SMILES_trimmer_cyclic\" if is_trimmer_cyclic else \"SMILES\"\n",
    "\n",
    "data_exp = \"exp040\"\n",
    "\n",
    "dataset_title = f\"model-{exp}\"\n",
    "dataset_id = f\"koya346/{dataset_title}\"\n",
    "\n",
    "if is_kaggle_notebook:\n",
    "    config[\"debug\"] = False\n",
    "\n",
    "if config[\"debug\"]:\n",
    "    config[\"n_splits\"] = 2\n",
    "    config[\"num_epochs\"] = 10\n",
    "\n",
    "targets = [\"Tg\", \"FFV\", \"Tc\", \"Density\", \"Rg\"]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "if isinstance(augmented_feature, str):\n",
    "    augmented_feature = eval(augmented_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16a10533-77cf-436d-8abf-a3ae32a17545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load train.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Density_mean_mae</td><td>‚ñÅ</td></tr><tr><td>FFV_mean_mae</td><td>‚ñÅ</td></tr><tr><td>Rg_mean_mae</td><td>‚ñÅ</td></tr><tr><td>Tc_mean_mae</td><td>‚ñÅ</td></tr><tr><td>Tg_mean_mae</td><td>‚ñÅ</td></tr><tr><td>wMAE</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Density_mean_mae</td><td>0.93931</td></tr><tr><td>FFV_mean_mae</td><td>0.35013</td></tr><tr><td>Notes</td><td></td></tr><tr><td>Rg_mean_mae</td><td>16.33129</td></tr><tr><td>Tc_mean_mae</td><td>0.23786</td></tr><tr><td>Tg_mean_mae</td><td>77.9222</td></tr><tr><td>wMAE</td><td>0.51839</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exp040_smiles_transformer</strong> at: <a href='https://wandb.ai/ko_ya346/opp2025/runs/ak0il5sm' target=\"_blank\">https://wandb.ai/ko_ya346/opp2025/runs/ak0il5sm</a><br> View project at: <a href='https://wandb.ai/ko_ya346/opp2025' target=\"_blank\">https://wandb.ai/ko_ya346/opp2025</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250820_235222-ak0il5sm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kouya-takahashi/kaggle/opp2025/notebook/wandb/run-20250821_001619-v0xz6bab</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ko_ya346/opp2025/runs/v0xz6bab' target=\"_blank\">exp040_smiles_transformer</a></strong> to <a href='https://wandb.ai/ko_ya346/opp2025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ko_ya346/opp2025' target=\"_blank\">https://wandb.ai/ko_ya346/opp2025</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ko_ya346/opp2025/runs/v0xz6bab' target=\"_blank\">https://wandb.ai/ko_ya346/opp2025/runs/v0xz6bab</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "model_name: smiles_transformer\n",
      "\n",
      "=== Fold 1 / 2 ===\n",
      "Fold 1 target: Tg MSE: 8267.8663 | MAE: 72.6873\n",
      "\n",
      "=== Fold 2 / 2 ===\n",
      "Fold 2 target: Tg MSE: 15149.5800 | MAE: 83.1588\n",
      "RMSE for Tg: 11708.7231\n",
      "MAE for Tg: 77.9230\n",
      "\n",
      "=== Fold 1 / 2 ===\n",
      "Fold 1 target: FFV MSE: 0.1247 | MAE: 0.3522\n",
      "\n",
      "=== Fold 2 / 2 ===\n",
      "Fold 2 target: FFV MSE: 0.1217 | MAE: 0.3479\n",
      "RMSE for FFV: 0.1232\n",
      "MAE for FFV: 0.3501\n",
      "\n",
      "=== Fold 1 / 2 ===\n",
      "Fold 1 target: Tc MSE: 0.0726 | MAE: 0.2467\n",
      "\n",
      "=== Fold 2 / 2 ===\n",
      "Fold 2 target: Tc MSE: 0.0615 | MAE: 0.2268\n",
      "RMSE for Tc: 0.0671\n",
      "MAE for Tc: 0.2369\n",
      "\n",
      "=== Fold 1 / 2 ===\n",
      "Fold 1 target: Density MSE: 0.8345 | MAE: 0.9038\n",
      "\n",
      "=== Fold 2 / 2 ===\n",
      "Fold 2 target: Density MSE: 0.9528 | MAE: 0.9697\n",
      "RMSE for Density: 0.8944\n",
      "MAE for Density: 0.9371\n",
      "\n",
      "=== Fold 1 / 2 ===\n",
      "Fold 1 target: Rg MSE: 285.9472 | MAE: 16.0584\n",
      "\n",
      "=== Fold 2 / 2 ===\n",
      "Fold 2 target: Rg MSE: 310.3715 | MAE: 16.6146\n",
      "RMSE for Rg: 298.0086\n",
      "MAE for Rg: 16.3331\n",
      "\n",
      "üìä Final OOF Score (wMAE): 0.517654\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# „É°„Ç§„É≥Âá¶ÁêÜ\n",
    "# ---------------------------\n",
    "if config[\"debug\"]:\n",
    "    output_path = Path(\"/home/kouya-takahashi/kaggle/opp2025/outputs\") / exp / \"debug\"\n",
    "    data_path = Path(\"/home/kouya-takahashi/kaggle/opp2025/outputs\") / exp / \"debug\"\n",
    "else:\n",
    "    output_path = Path(\"/home/kouya-takahashi/kaggle/opp2025/outputs\") / exp\n",
    "\n",
    "model_output_path = output_path / \"model\"\n",
    "if not os.path.exists(model_output_path):\n",
    "    os.makedirs(model_output_path)\n",
    "\n",
    "if is_kaggle_notebook:\n",
    "    # kaggle notebook\n",
    "    data_dir = Path(\"/kaggle/input\")\n",
    "else:\n",
    "    # local\n",
    "    data_dir = Path(\"/home/kouya-takahashi/kaggle/opp2025/data/raw\")\n",
    "\n",
    "if config[\"debug\"]:\n",
    "    train_path = Path(\"/home/kouya-takahashi/kaggle/opp2025/outputs\") / data_exp / \"train_debug.csv\"\n",
    "else:\n",
    "    train_path = Path(\"/home/kouya-takahashi/kaggle/opp2025/outputs\") / data_exp / \"train.csv\"\n",
    "\n",
    "    \n",
    "if os.path.exists(train_path):\n",
    "    print(\"Load train.csv\")\n",
    "    \n",
    "    train = pd.read_csv(train_path)\n",
    "else:\n",
    "    train, _ = load_data(data_dir)\n",
    "    \n",
    "    if config[\"debug\"]:\n",
    "        # ÂêÑ„Çø„Éº„Ç≤„ÉÉ„Éà„ÅåÊ¨†Êêç„Åó„Å¶„ÅÑ„Å™„ÅÑ„Éá„Éº„Çø„Çí30 ‰ª∂„Åö„Å§Âèñ„ÇäÂá∫„Åô\n",
    "        tmp_dfs = []\n",
    "        for target in targets:\n",
    "            cond = train[target].notnull()\n",
    "            tmp_dfs.append(train[cond].iloc[:30])\n",
    "        train = pd.concat(tmp_dfs).reset_index(drop=True)\n",
    "    else:\n",
    "        print(train.shape)\n",
    "        external_data_dict = [\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"neurips-open-polymer-prediction-2025/train_supplement/dataset3.csv\",\n",
    "                \"col\": \"Tg\",\n",
    "            },\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"neurips-open-polymer-prediction-2025/train_supplement/dataset1.csv\",\n",
    "                \"col\": \"Tc\",\n",
    "                \"rename_d\": {\"TC_mean\": \"Tc\"},\n",
    "            },\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"neurips-open-polymer-prediction-2025/train_supplement/dataset4.csv\",\n",
    "                \"col\": \"FFV\",\n",
    "            },\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"tg-smiles-pid-polymer-class/TgSS_enriched_cleaned.csv\",\n",
    "                \"col\": \"Tg\",\n",
    "            },\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"smiles-extra-data/data_dnst1.xlsx\",\n",
    "                \"col\": \"Density\",\n",
    "                \"rename_d\": {\"density(g/cm3)\": \"Density\"}, \n",
    "            },\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"smiles-extra-data/data_tg3.xlsx\",\n",
    "                \"col\": \"Tg\",\n",
    "                \"rename_d\": {\"Tg [K]\": \"Tg\"}, \n",
    "            },\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"smiles-extra-data/JCIM_sup_bigsmiles.csv\",\n",
    "                \"col\": \"Tg\",\n",
    "                \"rename_d\": {\"Tg (C)\": \"Tg\"}, \n",
    "            },\n",
    "        ]\n",
    "        for d in external_data_dict:\n",
    "            print(f\"ex_path: {str(d['ex_path'])}\")\n",
    "            train = add_external_data(\n",
    "                df=train,\n",
    "                ex_path=d.get(\"ex_path\"),\n",
    "                col=d.get(\"col\"),\n",
    "                rename_d=d.get(\"rename_d\"),\n",
    "                is_complement=config[\"is_complement\"]\n",
    "            )\n",
    "            print(\"after train.shape: \", train.shape)\n",
    "    \n",
    "    # „Éà„É™„Éû„ÉºÁí∞Áä∂ÂåñÂêàÁâ©„ÇíÁîüÊàê\n",
    "    if config[\"is_trimmer_cyclic\"]:\n",
    "        error_cnt = 0\n",
    "        trimer_smiles = []\n",
    "        for smiles in tqdm(train[\"SMILES\"].values):\n",
    "            try:\n",
    "                trimer_smiles.append(generate_trimer(smiles))\n",
    "            except ValueError as e:\n",
    "                print(f\"smiles: {smiles}, {e}\")\n",
    "                trimer_smiles.append(smiles)\n",
    "                error_cnt += 1\n",
    "        train[smiles_col] = trimer_smiles\n",
    "        print(f\"error smiles count: {error_cnt}\")\n",
    "    \n",
    "    train[\"SMILES\"] = train[\"SMILES\"].apply(make_smile_canonical)\n",
    "    train[\"scaffold\"] = train[\"SMILES\"].apply(generate_scaffold)\n",
    "    \n",
    "    # id „ÅåÊ¨†Êêç„Åó„Å¶„ÅÑ„Çã -> ËøΩÂä†„Éá„Éº„Çø\n",
    "    train[\"is_external\"] = train[\"id\"].isnull()\n",
    "    \n",
    "    train[\"id\"] = np.arange(len(train))\n",
    "    print(\"Save train.csv\")\n",
    "    train.to_csv(train_path, index=False)\n",
    "\n",
    "\n",
    "submission = pd.read_csv(\n",
    "    data_dir / \"neurips-open-polymer-prediction-2025/sample_submission.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "fold_results = []\n",
    "train_config = {\n",
    "    \"task_type\": \"regression\",\n",
    "    \"num_task\": 1,\n",
    "    \"batch_size\": config[\"batch_size\"],\n",
    "    \"augmented_feature\": augmented_feature,\n",
    "    \"epochs\": config[\"num_epochs\"],\n",
    "    \"drop_ratio\": config[\"drop_ratio\"],\n",
    "    \"patience\": 50,\n",
    "    \"scheduler_patience\": 5,\n",
    "    \"verbose\": False,\n",
    "    \"graph_pooling\": config[\"graph_pooling\"]\n",
    "}\n",
    "\n",
    "all_loss_tables = []\n",
    "for model_name in model_names:\n",
    "    train_model_config = train_config.copy()\n",
    "\n",
    "    # „É¢„Éá„É´„Å´„Çà„Å£„Å¶ÂºïÊï∞Â§â„Çè„Çã\n",
    "    if model_name == \"smiles_transformer\":\n",
    "        del train_model_config[\"augmented_feature\"], train_model_config[\"drop_ratio\"], train_model_config[\"graph_pooling\"]\n",
    "    \n",
    "    wandb_name = f\"{exp}_{model_name}\" if not config[\"debug\"] else f\"{exp}_{model_name}_debug\"\n",
    "    wandb.init(project=\"opp2025\", name=f\"{exp}_{model_name}\", config=config)\n",
    "    wandb.log({\"Notes\": notes})\n",
    "    loss_table = wandb.Table(columns=[\"exp\", \"model_name\", \"fold\", \"target\", \"mae\", \"mse\"])\n",
    "    oof_dfs = []\n",
    "    mae_dict = {}\n",
    "    \n",
    "    print(\"====================\")\n",
    "    print(f\"model_name: {model_name}\")\n",
    "\n",
    "    for target in targets:\n",
    "        cond = train[target].notnull()\n",
    "        df_train = train[cond]\n",
    "        df_train_org = df_train[~df_train[\"is_external\"]].reset_index(drop=True)\n",
    "        df_train_external = df_train[df_train[\"is_external\"]].reset_index(drop=True)\n",
    "        \n",
    "        df_train_idx = df_train_org[\"id\"].values\n",
    "        X_org = df_train_org[[smiles_col]]\n",
    "        y_org = df_train_org[target]\n",
    "        X_external = df_train_external[[smiles_col]]\n",
    "        y_external = df_train_external[target]\n",
    "        oof = np.zeros(len(X_org))\n",
    "\n",
    "        df_train_org = add_scaffold_kfold(df_train_org, n_splits=config[\"n_splits\"])\n",
    "        \n",
    "        for fold, train_idx, val_idx in scaffold_cv_split(df_train_org, n_splits=config[\"n_splits\"]):\n",
    "            print(f'\\n=== Fold {fold + 1} / {config[\"n_splits\"]} ===')\n",
    "\n",
    "            X_train = pd.concat([X_org.iloc[train_idx][smiles_col], X_external[smiles_col]]).to_list()\n",
    "            y_train = pd.concat([y_org.iloc[train_idx], y_external]).to_numpy()\n",
    "            X_val = X_org.iloc[val_idx][smiles_col].to_list()\n",
    "            y_val = y_org.iloc[val_idx].to_numpy()\n",
    "    \n",
    "            model = get_model(model_name)(**train_model_config)\n",
    "            #     task_type=\"regression\",\n",
    "            #     num_task=1,\n",
    "            #     batch_size=config[\"batch_size\"],\n",
    "            #     # augmented_feature=augmented_feature,\n",
    "            #     epochs=config[\"num_epochs\"],\n",
    "            #     # drop_ratio=config[\"drop_ratio\"],\n",
    "            #     patience=50,\n",
    "            #     scheduler_patience=5,\n",
    "            #     verbose=False,\n",
    "            #     # graph_pooling=config[\"graph_pooling\"]\n",
    "            # )\n",
    "            model.fit(\n",
    "                # gnn.autofit(\n",
    "                X_train=X_train,\n",
    "                y_train=y_train,\n",
    "                X_val=X_val,\n",
    "                y_val=y_val,\n",
    "                # n_trials=1,\n",
    "            )\n",
    "            save_model_path = model_output_path / f\"{model_name}_{fold}_{target}.pt\"\n",
    "            model.save(path=str(save_model_path))\n",
    "    \n",
    "            preds = model.predict(X_val)[\"prediction\"].flatten()\n",
    "            oof[val_idx] = preds\n",
    "            \n",
    "            mse = mean_squared_error(y_val, preds)\n",
    "            mae = mean_absolute_error(y_val, preds)\n",
    "            print(f\"Fold {fold+1} target: {target} MSE: {mse:.4f} | MAE: {mae:.4f}\")\n",
    "            loss_table.add_data(exp, model_name, fold, target, mae, mse)\n",
    "\n",
    "            all_loss_tables.append({\"target\": target, \"fold\": fold, \"mae\": mae})\n",
    "            \n",
    "        score_mse = mean_squared_error(y_org, oof)\n",
    "        score_mae = mean_absolute_error(y_org, oof)\n",
    "        print(f\"RMSE for {target}: {score_mse:.4f}\")\n",
    "        print(f\"MAE for {target}: {score_mae:.4f}\")\n",
    "        mae_dict[target] = score_mae\n",
    "\n",
    "        oof_df = pd.DataFrame({\n",
    "            \"id\": df_train_idx,\n",
    "            target: oof            \n",
    "        })\n",
    "        oof_dfs.append(oof_df)\n",
    "\n",
    "        wandb.log({f\"fold_target_losses\": loss_table})\n",
    "\n",
    "    # CV Ë®àÁÆó\n",
    "    oof_df = pd.DataFrame()\n",
    "    oof_df[\"id\"] = train.loc[~train[\"is_external\"], \"id\"]\n",
    "    for i_oof in oof_dfs:\n",
    "        oof_df = oof_df.merge(i_oof, on=\"id\", how=\"left\")\n",
    "    solution = train.loc[~train[\"is_external\"], [\"id\"] + targets].copy()\n",
    "    solution = solution.fillna(NULL_FOR_SUBMISSION)\n",
    "    oof_df = oof_df.fillna(NULL_FOR_SUBMISSION)\n",
    "    \n",
    "    # Ë©ï‰æ°\n",
    "    final_score = score(\n",
    "        solution=solution,\n",
    "        submission=oof_df,\n",
    "    )\n",
    "    print(f\"\\nüìä Final OOF Score (wMAE): {final_score:.6f}\")\n",
    "    wandb.log({\"wMAE\": final_score})\n",
    "\n",
    "    oof_df.to_csv(output_path / f\"oof_{model_name}.csv\", index=False)\n",
    "\n",
    "    \n",
    "    # target ÊØé„ÅÆ Âπ≥Âùá mae „ÇíË®òÈå≤\n",
    "    for target in targets:\n",
    "        key_name = f\"{target}_mean_mae\"\n",
    "        mae_values = mae_dict[target]\n",
    "        # mae_values = [d[\"mae\"] for d in all_loss_tables if d[\"target\"] == target]\n",
    "        wandb.log({key_name: np.mean(mae_values)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e091d4fc-9b99-46de-b9c5-3de68ead0883",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config[\"debug\"]:\n",
    "    create_kaggle_dataset_metadata(dataset_title, dataset_id, model_output_path)\n",
    "    upload_kaggle_dataset(dataset_id, model_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fac62ac-b723-4212-af75-714ebd150c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3} {'b': 2, 'c': 3}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# dict „Çí„Ç≥„Éî„Éº„Åó„Å¶„Ç≠„ÉºÂâäÈô§„Åó„Åü„ÅÑ\n",
    "d = {\"a\": 1, \"b\": 2, \"c\": 3}\n",
    "dd = d.copy()\n",
    "\n",
    "del dd[\"a\"]\n",
    "print(d, dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c585f209-6d5f-4ae7-a0ee-3f1efa71fbca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opp2025_myenv",
   "language": "python",
   "name": "opp2025_myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
