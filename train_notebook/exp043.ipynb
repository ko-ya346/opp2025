{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "634a0b10-991b-4d14-b39c-6507c6bcb418",
   "metadata": {},
   "source": [
    "- -> exp042\n",
    "- `data/preprocess/fold/folds.csv` „ÇíÂëº„Å≥Âá∫„Åó„Å¶ fold „Çí‰ªò‰∏é„Åô„Çã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa7a2c22-eb3e-479e-8f1f-9f9b50a176ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autotime\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7174264-b9fd-41b5-91fe-f5174dd30852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "is_kaggle_notebook = os.path.exists(\"/kaggle/input\")\n",
    "\n",
    "# ÂøÖË¶Å„Éë„ÉÉ„Ç±„Éº„Ç∏„Çí„Ç§„É≥„Çπ„Éà„Éº„É´\n",
    "if is_kaggle_notebook:\n",
    "    !pip install /kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl\n",
    "    !pip install /kaggle/input/torch-geometric-2-6-1/torch_geometric-2.6.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f929c2-afe2-4fcb-986b-6f50075faa7a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mko_ya346\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import wandb\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from rdkit import rdBase\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GroupKFold, KFold\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "rdBase.DisableLog(\"rdApp.warning\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de6f94aa-f4e5-4b14-8bad-f9f73cd60375",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "pr_number = 1\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ccadd16-5880-496e-a632-4d5940b2266c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "if is_kaggle_notebook:\n",
    "    module_path = f\"/kaggle/input/myproject-pr-{pr_number:04}\"\n",
    "    !mkdir src\n",
    "    !cp -r $module_path/* src/\n",
    "    src_path = \"./\"\n",
    "else:\n",
    "    src_path = \"../\"\n",
    "\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from src.data import load_data, add_descriptors, add_external_data, make_smile_canonical, add_maccs, add_augumented_gmm, add_graph_features, add_count_atoms\n",
    "from src.model import train_lgb_for_target, save_lgb_model\n",
    "from src.utils import NULL_FOR_SUBMISSION, generate_scaffold, score, add_scaffold_kfold, scaffold_cv_split, get_useless_cols\n",
    "from src.utils.upload_kaggle_dataset import (\n",
    "    create_kaggle_dataset_metadata,\n",
    "    upload_kaggle_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef59d0f-f03f-4636-9839-c8cbc2b4cfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"exp043\"\n",
    "notes = \"Âõ∫ÂÆö fold\"\n",
    "model_name = \"lgb\"\n",
    "\n",
    "config = {\n",
    "    \"debug\": debug,\n",
    "    \"n_splits\": 3,\n",
    "    \"num_epochs\": 1000,\n",
    "    \"batch_size\": 128,\n",
    "    \"drop_ratio\": 0.5,\n",
    "    \"force_update_train\": False,\n",
    "    \"augumented_gmm\": False,\n",
    "    \"is_complement\": True\n",
    "}\n",
    "\n",
    "dataset_title = f\"model-{exp}\"\n",
    "dataset_id = f\"koya346/{dataset_title}\"\n",
    "\n",
    "if is_kaggle_notebook:\n",
    "    config[\"debug\"] = False\n",
    "\n",
    "if config[\"debug\"]:\n",
    "    config[\"n_splits\"] = 2\n",
    "    config[\"num_epochs\"] = 10\n",
    "\n",
    "targets = [\"Tg\", \"FFV\", \"Tc\", \"Density\", \"Rg\"]\n",
    "\n",
    "# TODO: Â≠¶Áøí„Éë„É©„É°„Éº„ÇøÂÆöÁæ©\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"mae\",\n",
    "    \"verbosity\": -1,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"max_depth\": 7,\n",
    "    \"seed\": 42,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.6,\n",
    "    \"num_boost_round\": 20000,\n",
    "}\n",
    "\n",
    "config.update(params)\n",
    "pre_params = copy.deepcopy(params)\n",
    "pre_params[\"num_boost_round\"] = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16a10533-77cf-436d-8abf-a3ae32a17545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Density_mean_mae</td><td>‚ñÅ</td></tr><tr><td>FFV_mean_mae</td><td>‚ñÅ</td></tr><tr><td>Rg_mean_mae</td><td>‚ñÅ</td></tr><tr><td>Tc_mean_mae</td><td>‚ñÅ</td></tr><tr><td>Tg_mean_mae</td><td>‚ñÅ</td></tr><tr><td>wMAE</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Density_mean_mae</td><td>0.05902</td></tr><tr><td>FFV_mean_mae</td><td>0.0079</td></tr><tr><td>Notes</td><td>Âõ∫ÂÆö fold</td></tr><tr><td>Rg_mean_mae</td><td>2.02944</td></tr><tr><td>Tc_mean_mae</td><td>0.03757</td></tr><tr><td>Tg_mean_mae</td><td>33.39002</td></tr><tr><td>wMAE</td><td>0.06492</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exp043_lgb</strong> at: <a href='https://wandb.ai/ko_ya346/opp2025/runs/983dpyze' target=\"_blank\">https://wandb.ai/ko_ya346/opp2025/runs/983dpyze</a><br> View project at: <a href='https://wandb.ai/ko_ya346/opp2025' target=\"_blank\">https://wandb.ai/ko_ya346/opp2025</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250824_134852-983dpyze/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "creating run (0.0s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kouya-takahashi/kaggle/opp2025/notebook/wandb/run-20250824_135049-6926ygvm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ko_ya346/opp2025/runs/6926ygvm' target=\"_blank\">exp043_lgb</a></strong> to <a href='https://wandb.ai/ko_ya346/opp2025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ko_ya346/opp2025' target=\"_blank\">https://wandb.ai/ko_ya346/opp2025</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ko_ya346/opp2025/runs/6926ygvm' target=\"_blank\">https://wandb.ai/ko_ya346/opp2025/runs/6926ygvm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312\n",
      "\n",
      "=== Training for target: Tg ===\n",
      "fold: 1\n",
      "0.6791158536585366\n",
      "421\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 33.9481\tvalid_1's l1: 54.7389\n",
      "[400]\ttraining's l1: 25.4995\tvalid_1's l1: 45.1916\n",
      "[600]\ttraining's l1: 22.5012\tvalid_1's l1: 42.5274\n",
      "[800]\ttraining's l1: 20.5972\tvalid_1's l1: 41.2277\n",
      "[1000]\ttraining's l1: 19.105\tvalid_1's l1: 39.927\n",
      "[1200]\ttraining's l1: 17.8629\tvalid_1's l1: 39.2893\n",
      "[1400]\ttraining's l1: 16.7587\tvalid_1's l1: 38.8824\n",
      "[1600]\ttraining's l1: 15.7774\tvalid_1's l1: 38.5571\n",
      "[1800]\ttraining's l1: 14.9182\tvalid_1's l1: 38.2228\n",
      "[2000]\ttraining's l1: 14.2029\tvalid_1's l1: 38.0066\n",
      "[2200]\ttraining's l1: 13.5199\tvalid_1's l1: 37.8236\n",
      "[2400]\ttraining's l1: 12.9407\tvalid_1's l1: 37.6536\n",
      "[2600]\ttraining's l1: 12.3777\tvalid_1's l1: 37.5171\n",
      "Early stopping, best iteration is:\n",
      "[2595]\ttraining's l1: 12.3946\tvalid_1's l1: 37.5146\n",
      "fold: 2\n",
      "0.6775914634146342\n",
      "423\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 34.9619\tvalid_1's l1: 42.6552\n",
      "[400]\ttraining's l1: 25.7609\tvalid_1's l1: 36.5155\n",
      "[600]\ttraining's l1: 22.6775\tvalid_1's l1: 34.8871\n",
      "[800]\ttraining's l1: 20.7447\tvalid_1's l1: 34.1059\n",
      "[1000]\ttraining's l1: 19.2943\tvalid_1's l1: 33.6236\n",
      "[1200]\ttraining's l1: 18.0469\tvalid_1's l1: 33.3264\n",
      "[1400]\ttraining's l1: 16.9773\tvalid_1's l1: 33.1182\n",
      "[1600]\ttraining's l1: 16.0086\tvalid_1's l1: 33.009\n",
      "[1800]\ttraining's l1: 15.1593\tvalid_1's l1: 32.908\n",
      "[2000]\ttraining's l1: 14.4178\tvalid_1's l1: 32.8218\n",
      "[2200]\ttraining's l1: 13.7917\tvalid_1's l1: 32.7594\n",
      "[2400]\ttraining's l1: 13.1699\tvalid_1's l1: 32.6901\n",
      "[2600]\ttraining's l1: 12.5971\tvalid_1's l1: 32.6527\n",
      "[2800]\ttraining's l1: 12.0761\tvalid_1's l1: 32.6211\n",
      "[3000]\ttraining's l1: 11.5417\tvalid_1's l1: 32.5978\n",
      "Early stopping, best iteration is:\n",
      "[2983]\ttraining's l1: 11.5857\tvalid_1's l1: 32.5966\n",
      "fold: 3\n",
      "0.6989329268292683\n",
      "395\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 36.3044\tvalid_1's l1: 37.5477\n",
      "[400]\ttraining's l1: 26.9611\tvalid_1's l1: 31.8315\n",
      "[600]\ttraining's l1: 23.639\tvalid_1's l1: 30.453\n",
      "[800]\ttraining's l1: 21.6772\tvalid_1's l1: 29.836\n",
      "[1000]\ttraining's l1: 20.1641\tvalid_1's l1: 29.5182\n",
      "[1200]\ttraining's l1: 18.9825\tvalid_1's l1: 29.3088\n",
      "[1400]\ttraining's l1: 17.9693\tvalid_1's l1: 29.1443\n",
      "[1600]\ttraining's l1: 17.0917\tvalid_1's l1: 29.0322\n",
      "[1800]\ttraining's l1: 16.2141\tvalid_1's l1: 28.9273\n",
      "[2000]\ttraining's l1: 15.4476\tvalid_1's l1: 28.8667\n",
      "[2200]\ttraining's l1: 14.7413\tvalid_1's l1: 28.8217\n",
      "Early stopping, best iteration is:\n",
      "[2291]\ttraining's l1: 14.4339\tvalid_1's l1: 28.8066\n",
      "RMSE for Tg: 2170.7334\n",
      "MAE for Tg: 33.0292\n",
      "\n",
      "=== Training for target: FFV ===\n",
      "fold: 1\n",
      "0.711890243902439\n",
      "378\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 0.00826087\tvalid_1's l1: 0.0127208\n",
      "[400]\ttraining's l1: 0.00598669\tvalid_1's l1: 0.0113076\n",
      "[600]\ttraining's l1: 0.00523751\tvalid_1's l1: 0.0108834\n",
      "[800]\ttraining's l1: 0.00479915\tvalid_1's l1: 0.0106707\n",
      "[1000]\ttraining's l1: 0.00450395\tvalid_1's l1: 0.010585\n",
      "Early stopping, best iteration is:\n",
      "[1148]\ttraining's l1: 0.00430561\tvalid_1's l1: 0.0105104\n",
      "fold: 2\n",
      "0.7073170731707317\n",
      "384\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 0.00893425\tvalid_1's l1: 0.0106385\n",
      "[400]\ttraining's l1: 0.00651944\tvalid_1's l1: 0.00901977\n",
      "[600]\ttraining's l1: 0.00565806\tvalid_1's l1: 0.00852732\n",
      "[800]\ttraining's l1: 0.00511671\tvalid_1's l1: 0.00827433\n",
      "[1000]\ttraining's l1: 0.0047182\tvalid_1's l1: 0.00811866\n",
      "[1200]\ttraining's l1: 0.00441109\tvalid_1's l1: 0.00800559\n",
      "[1400]\ttraining's l1: 0.00415747\tvalid_1's l1: 0.00791461\n",
      "[1600]\ttraining's l1: 0.00393608\tvalid_1's l1: 0.00783357\n",
      "[1800]\ttraining's l1: 0.00375823\tvalid_1's l1: 0.00777102\n",
      "[2000]\ttraining's l1: 0.00360074\tvalid_1's l1: 0.00771418\n",
      "[2200]\ttraining's l1: 0.00346287\tvalid_1's l1: 0.00767264\n",
      "[2400]\ttraining's l1: 0.00333751\tvalid_1's l1: 0.00764156\n",
      "[2600]\ttraining's l1: 0.00322002\tvalid_1's l1: 0.00760736\n",
      "[2800]\ttraining's l1: 0.00311236\tvalid_1's l1: 0.00757417\n",
      "[3000]\ttraining's l1: 0.00301296\tvalid_1's l1: 0.00754131\n",
      "[3200]\ttraining's l1: 0.00291833\tvalid_1's l1: 0.00750955\n",
      "[3400]\ttraining's l1: 0.00281857\tvalid_1's l1: 0.00747825\n",
      "[3600]\ttraining's l1: 0.00273309\tvalid_1's l1: 0.00745042\n",
      "[3800]\ttraining's l1: 0.00265253\tvalid_1's l1: 0.00742826\n",
      "[4000]\ttraining's l1: 0.00257961\tvalid_1's l1: 0.00741004\n",
      "[4200]\ttraining's l1: 0.00250757\tvalid_1's l1: 0.00739378\n",
      "[4400]\ttraining's l1: 0.00243159\tvalid_1's l1: 0.007378\n",
      "[4600]\ttraining's l1: 0.00236173\tvalid_1's l1: 0.00736297\n",
      "[4800]\ttraining's l1: 0.00229526\tvalid_1's l1: 0.00735189\n",
      "[5000]\ttraining's l1: 0.00222817\tvalid_1's l1: 0.00733795\n",
      "[5200]\ttraining's l1: 0.00216306\tvalid_1's l1: 0.00732879\n",
      "[5400]\ttraining's l1: 0.00209654\tvalid_1's l1: 0.00731595\n",
      "[5600]\ttraining's l1: 0.00203723\tvalid_1's l1: 0.00730546\n",
      "[5800]\ttraining's l1: 0.00197904\tvalid_1's l1: 0.00729626\n",
      "[6000]\ttraining's l1: 0.00192474\tvalid_1's l1: 0.00728752\n",
      "[6200]\ttraining's l1: 0.00186474\tvalid_1's l1: 0.00727917\n",
      "[6400]\ttraining's l1: 0.00180524\tvalid_1's l1: 0.00727008\n",
      "[6600]\ttraining's l1: 0.00174576\tvalid_1's l1: 0.0072656\n",
      "[6800]\ttraining's l1: 0.00168551\tvalid_1's l1: 0.00726096\n",
      "[7000]\ttraining's l1: 0.00162762\tvalid_1's l1: 0.00725507\n",
      "[7200]\ttraining's l1: 0.00157979\tvalid_1's l1: 0.0072503\n",
      "[7400]\ttraining's l1: 0.00153351\tvalid_1's l1: 0.00724524\n",
      "[7600]\ttraining's l1: 0.00148621\tvalid_1's l1: 0.00724008\n",
      "Early stopping, best iteration is:\n",
      "[7633]\ttraining's l1: 0.00147789\tvalid_1's l1: 0.00723904\n",
      "fold: 3\n",
      "0.7172256097560976\n",
      "371\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 0.00928803\tvalid_1's l1: 0.00974196\n",
      "[400]\ttraining's l1: 0.00674206\tvalid_1's l1: 0.00809516\n",
      "[600]\ttraining's l1: 0.00579278\tvalid_1's l1: 0.00748233\n",
      "[800]\ttraining's l1: 0.00523956\tvalid_1's l1: 0.00717223\n",
      "[1000]\ttraining's l1: 0.00480704\tvalid_1's l1: 0.00696522\n",
      "[1200]\ttraining's l1: 0.00450951\tvalid_1's l1: 0.00682213\n",
      "[1400]\ttraining's l1: 0.00427236\tvalid_1's l1: 0.0067135\n",
      "[1600]\ttraining's l1: 0.00406996\tvalid_1's l1: 0.00661902\n",
      "[1800]\ttraining's l1: 0.00391273\tvalid_1's l1: 0.00655405\n",
      "[2000]\ttraining's l1: 0.00375944\tvalid_1's l1: 0.00650043\n",
      "[2200]\ttraining's l1: 0.00362547\tvalid_1's l1: 0.00644753\n",
      "[2400]\ttraining's l1: 0.00351196\tvalid_1's l1: 0.00640814\n",
      "[2600]\ttraining's l1: 0.00339578\tvalid_1's l1: 0.00636362\n",
      "[2800]\ttraining's l1: 0.00328815\tvalid_1's l1: 0.006324\n",
      "[3000]\ttraining's l1: 0.00317506\tvalid_1's l1: 0.00629047\n",
      "[3200]\ttraining's l1: 0.00308144\tvalid_1's l1: 0.00626311\n",
      "[3400]\ttraining's l1: 0.00298472\tvalid_1's l1: 0.0062329\n",
      "[3600]\ttraining's l1: 0.00289836\tvalid_1's l1: 0.00620826\n",
      "[3800]\ttraining's l1: 0.00281451\tvalid_1's l1: 0.00618828\n",
      "[4000]\ttraining's l1: 0.00272849\tvalid_1's l1: 0.00616392\n",
      "[4200]\ttraining's l1: 0.00264737\tvalid_1's l1: 0.00614637\n",
      "[4400]\ttraining's l1: 0.00257\tvalid_1's l1: 0.00612963\n",
      "[4600]\ttraining's l1: 0.00250188\tvalid_1's l1: 0.0061154\n",
      "[4800]\ttraining's l1: 0.00243803\tvalid_1's l1: 0.00610314\n",
      "[5000]\ttraining's l1: 0.0023822\tvalid_1's l1: 0.00609211\n",
      "[5200]\ttraining's l1: 0.00231862\tvalid_1's l1: 0.00607742\n",
      "[5400]\ttraining's l1: 0.0022583\tvalid_1's l1: 0.00606708\n",
      "[5600]\ttraining's l1: 0.00219873\tvalid_1's l1: 0.00605757\n",
      "[5800]\ttraining's l1: 0.00214017\tvalid_1's l1: 0.00604763\n",
      "[6000]\ttraining's l1: 0.00208375\tvalid_1's l1: 0.00603685\n",
      "[6200]\ttraining's l1: 0.00202498\tvalid_1's l1: 0.0060338\n",
      "[6400]\ttraining's l1: 0.0019705\tvalid_1's l1: 0.00602709\n",
      "[6600]\ttraining's l1: 0.00191156\tvalid_1's l1: 0.00602001\n",
      "[6800]\ttraining's l1: 0.00185577\tvalid_1's l1: 0.00601239\n",
      "[7000]\ttraining's l1: 0.00180221\tvalid_1's l1: 0.0060061\n",
      "[7200]\ttraining's l1: 0.00175085\tvalid_1's l1: 0.00600038\n",
      "Early stopping, best iteration is:\n",
      "[7346]\ttraining's l1: 0.00171049\tvalid_1's l1: 0.005997\n",
      "RMSE for FFV: 0.0002\n",
      "MAE for FFV: 0.0078\n",
      "\n",
      "=== Training for target: Tc ===\n",
      "fold: 1\n",
      "0.8734756097560976\n",
      "166\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 0.0293716\tvalid_1's l1: 0.0368312\n",
      "[400]\ttraining's l1: 0.0234752\tvalid_1's l1: 0.0342318\n",
      "[600]\ttraining's l1: 0.0207831\tvalid_1's l1: 0.0339813\n",
      "Early stopping, best iteration is:\n",
      "[586]\ttraining's l1: 0.0209398\tvalid_1's l1: 0.033948\n",
      "fold: 2\n",
      "0.8673780487804879\n",
      "174\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 0.0259285\tvalid_1's l1: 0.0396846\n",
      "[400]\ttraining's l1: 0.0202257\tvalid_1's l1: 0.0343072\n",
      "[600]\ttraining's l1: 0.0182861\tvalid_1's l1: 0.0335282\n",
      "[800]\ttraining's l1: 0.0171571\tvalid_1's l1: 0.0330291\n",
      "Early stopping, best iteration is:\n",
      "[923]\ttraining's l1: 0.0165356\tvalid_1's l1: 0.0329455\n",
      "fold: 3\n",
      "0.8673780487804879\n",
      "174\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 0.0223361\tvalid_1's l1: 0.0581771\n",
      "[400]\ttraining's l1: 0.0161613\tvalid_1's l1: 0.0557842\n",
      "Early stopping, best iteration is:\n",
      "[495]\ttraining's l1: 0.0150923\tvalid_1's l1: 0.0556288\n",
      "RMSE for Tc: 0.0051\n",
      "MAE for Tc: 0.0378\n",
      "\n",
      "=== Training for target: Density ===\n",
      "fold: 1\n",
      "0.9077743902439024\n",
      "121\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 0.0335679\tvalid_1's l1: 0.077519\n",
      "[400]\ttraining's l1: 0.0227966\tvalid_1's l1: 0.0692613\n",
      "[600]\ttraining's l1: 0.0183244\tvalid_1's l1: 0.0670983\n",
      "[800]\ttraining's l1: 0.0154302\tvalid_1's l1: 0.0667993\n",
      "Early stopping, best iteration is:\n",
      "[759]\ttraining's l1: 0.0159885\tvalid_1's l1: 0.0665188\n",
      "fold: 2\n",
      "0.8932926829268293\n",
      "140\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 0.0312401\tvalid_1's l1: 0.051003\n",
      "[400]\ttraining's l1: 0.0207984\tvalid_1's l1: 0.0445915\n",
      "[600]\ttraining's l1: 0.0172626\tvalid_1's l1: 0.0427392\n",
      "Early stopping, best iteration is:\n",
      "[642]\ttraining's l1: 0.0167409\tvalid_1's l1: 0.042637\n",
      "fold: 3\n",
      "0.9009146341463414\n",
      "130\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 0.0290121\tvalid_1's l1: 0.0575457\n",
      "Early stopping, best iteration is:\n",
      "[227]\ttraining's l1: 0.0260459\tvalid_1's l1: 0.0570895\n",
      "RMSE for Density: 0.0111\n",
      "MAE for Density: 0.0587\n",
      "\n",
      "=== Training for target: Rg ===\n",
      "fold: 1\n",
      "0.895579268292683\n",
      "137\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 1.45501\tvalid_1's l1: 2.31922\n",
      "[400]\ttraining's l1: 1.03032\tvalid_1's l1: 2.02653\n",
      "[600]\ttraining's l1: 0.809406\tvalid_1's l1: 1.97952\n",
      "Early stopping, best iteration is:\n",
      "[695]\ttraining's l1: 0.734508\tvalid_1's l1: 1.97419\n",
      "fold: 2\n",
      "0.8833841463414634\n",
      "153\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 1.41094\tvalid_1's l1: 1.93474\n",
      "[400]\ttraining's l1: 1.01282\tvalid_1's l1: 1.73106\n",
      "Early stopping, best iteration is:\n",
      "[534]\ttraining's l1: 0.922979\tvalid_1's l1: 1.7152\n",
      "fold: 3\n",
      "0.8803353658536586\n",
      "157\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 1.26987\tvalid_1's l1: 2.82363\n",
      "[400]\ttraining's l1: 0.931061\tvalid_1's l1: 2.57685\n",
      "[600]\ttraining's l1: 0.81893\tvalid_1's l1: 2.55391\n",
      "[800]\ttraining's l1: 0.725427\tvalid_1's l1: 2.53731\n",
      "Early stopping, best iteration is:\n",
      "[752]\ttraining's l1: 0.744198\tvalid_1's l1: 2.53617\n",
      "RMSE for Rg: 8.4904\n",
      "MAE for Rg: 2.0159\n",
      "\n",
      "üìä Final OOF Score (wMAE): 0.064744\n",
      "{'Tg': [2595, 2983, 2291], 'FFV': [1148, 7633, 7346], 'Tc': [586, 923, 495], 'Density': [759, 642, 227], 'Rg': [695, 534, 752]}\n"
     ]
    }
   ],
   "source": [
    "wandb_name = f\"{exp}_{model_name}\" if not config[\"debug\"] else f\"{exp}_{model_name}_debug\"\n",
    "wandb.init(project=\"opp2025\", name=wandb_name, config=config)\n",
    "wandb.log({\"Notes\": notes})\n",
    "\n",
    "# ---------------------------\n",
    "# „É°„Ç§„É≥Âá¶ÁêÜ\n",
    "# ---------------------------\n",
    "if config[\"debug\"]:\n",
    "    output_path = Path(\"/home/kouya-takahashi/kaggle/opp2025/outputs\") / exp / \"debug\"\n",
    "else:\n",
    "    output_path = Path(\"/home/kouya-takahashi/kaggle/opp2025/outputs\") / exp\n",
    "\n",
    "model_output_path = output_path / \"model_cv\"\n",
    "if not os.path.exists(model_output_path):\n",
    "    os.makedirs(model_output_path)\n",
    "\n",
    "if is_kaggle_notebook:\n",
    "    # kaggle notebook\n",
    "    data_dir = Path(\"/kaggle/input\")\n",
    "else:\n",
    "    # local\n",
    "    data_dir = Path(\"/home/kouya-takahashi/kaggle/opp2025/data/raw\")\n",
    "\n",
    "# Â≠¶Áøí„Éá„Éº„ÇøÁî®ÊÑè\n",
    "\n",
    "if os.path.exists(output_path / \"train.csv\") and not config[\"force_update_train\"]:\n",
    "    train = pd.read_csv(output_path / \"train.csv\")\n",
    "else:\n",
    "    train, _ = load_data(data_dir)\n",
    "    train[\"SMILES\"] = train[\"SMILES\"].apply(make_smile_canonical)\n",
    "\n",
    "    if config[\"debug\"]:\n",
    "        # ÂêÑ„Çø„Éº„Ç≤„ÉÉ„Éà„ÅåÊ¨†Êêç„Åó„Å¶„ÅÑ„Å™„ÅÑ„Éá„Éº„Çø„Çí30 ‰ª∂„Åö„Å§Âèñ„ÇäÂá∫„Åô\n",
    "        tmp_dfs = []\n",
    "        for target in targets:\n",
    "            cond = train[target].notnull()\n",
    "            tmp_dfs.append(train[cond].iloc[:30])\n",
    "        train = pd.concat(tmp_dfs).reset_index(drop=True)\n",
    "    else:\n",
    "        print(train.shape)\n",
    "        external_data_dict = [\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"neurips-open-polymer-prediction-2025/train_supplement/dataset3.csv\",\n",
    "                \"col\": \"Tg\",\n",
    "            },\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"neurips-open-polymer-prediction-2025/train_supplement/dataset1.csv\",\n",
    "                \"col\": \"Tc\",\n",
    "                \"rename_d\": {\"TC_mean\": \"Tc\"},\n",
    "            },\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"neurips-open-polymer-prediction-2025/train_supplement/dataset4.csv\",\n",
    "                \"col\": \"FFV\",\n",
    "            },\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"tg-smiles-pid-polymer-class/TgSS_enriched_cleaned.csv\",\n",
    "                \"col\": \"Tg\",\n",
    "            },\n",
    "            # {\n",
    "            #     \"ex_path\": data_dir / \"smiles-extra-data/data_dnst1.xlsx\",\n",
    "            #     \"col\": \"Density\",\n",
    "            #     \"rename_d\": {\"density(g/cm3)\": \"Density\"}, \n",
    "            # },\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"smiles-extra-data/data_tg3.xlsx\",\n",
    "                \"col\": \"Tg\",\n",
    "                \"rename_d\": {\"Tg [K]\": \"Tg\"}, \n",
    "            },\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"smiles-extra-data/JCIM_sup_bigsmiles.csv\",\n",
    "                \"col\": \"Tg\",\n",
    "                \"rename_d\": {\"Tg (C)\": \"Tg\"}, \n",
    "            },\n",
    "        ]\n",
    "        for d in external_data_dict:\n",
    "            print(f\"ex_path: {str(d['ex_path'])}\")\n",
    "            train = add_external_data(\n",
    "                df=train,\n",
    "                ex_path=d.get(\"ex_path\"),\n",
    "                col=d.get(\"col\"),\n",
    "                rename_d=d.get(\"rename_d\"),\n",
    "                is_complement=config[\"is_complement\"]\n",
    "            )\n",
    "            print(\"after train.shape: \", train.shape)\n",
    "\n",
    "    train = add_maccs(train)\n",
    "\n",
    "    # rdkit „ÅÆË®òËø∞Â≠ê, morgan finger print\n",
    "    train = add_descriptors(train, radius=2, fp_size=1024)\n",
    "\n",
    "    new_cols = []\n",
    "    seen = {}\n",
    "    for col in train.columns:\n",
    "        if col in seen:\n",
    "            seen[col] += 1\n",
    "            new_cols.append(f\"{col}_{seen[col]}\")\n",
    "        else:\n",
    "            seen[col] = 0\n",
    "            new_cols.append(col)\n",
    "    \n",
    "    train.columns = new_cols\n",
    "    \n",
    "    # id „ÅåÊ¨†Êêç„Åó„Å¶„ÅÑ„Çã -> ËøΩÂä†„Éá„Éº„Çø\n",
    "    train[\"is_external\"] = train[\"id\"].isnull()\n",
    "    \n",
    "    # „Ç∞„É©„ÉïÁâπÂæ¥Èáè\n",
    "    train = add_graph_features(train)\n",
    "    train = add_count_atoms(train)\n",
    "    \n",
    "    train[\"id\"] = np.arange(len(train))\n",
    "    features = train.drop(targets + [\"id\", \"SMILES\"], axis=1).columns\n",
    "    for col in features:\n",
    "        if train[col].dtype == \"object\":\n",
    "            train[col] = pd.to_numeric(train[col], errors=\"coerce\")\n",
    "    useless_cols = get_useless_cols(train.drop(targets + [\"id\", \"SMILES\"], axis=1))\n",
    "    \n",
    "    train = train.drop(useless_cols, axis=1)\n",
    "    \n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    train.to_csv(output_path / \"train.csv\", index=False)\n",
    "    print(\"Saved train.csv\")\n",
    "\n",
    "folds = pd.read_csv(\"../data/preprocess/fold/folds.csv\")\n",
    "train = train.merge(folds[[\"SMILES\", \"fold\"]], how=\"left\", on=\"SMILES\")\n",
    "\n",
    "features = train.drop(targets + [\"id\", \"SMILES\", \"fold\"], axis=1).columns\n",
    "print(len(features))\n",
    "\n",
    "oof_dfs = []\n",
    "\n",
    "loss_table_wandb = wandb.Table([\"exp\", \"model_name\", \"fold\", \"target\", \"mae\", \"mse\"])\n",
    "all_loss_tables = []\n",
    "mae_dict = {}\n",
    "all_models = {}\n",
    "\n",
    "for idx, target_col in enumerate(targets):\n",
    "    loss_tables = []\n",
    "    print(f\"\\n=== Training for target: {target_col} ===\")\n",
    "\n",
    "    df_train = train[train[target_col].notnull()].reset_index(drop=True)\n",
    "    X = df_train[features]\n",
    "    y = df_train[target_col]\n",
    "    oof = np.zeros(len(X))\n",
    "    \n",
    "    models = []\n",
    "\n",
    "    for fold, tr_idx, val_idx in scaffold_cv_split(df_train, n_splits=config[\"n_splits\"]):\n",
    "        loss_table = {}\n",
    "        print(f\"fold: {fold + 1}\")\n",
    "        if target_col in targets and not config[\"debug\"]:\n",
    "            X_train_pre = X.iloc[tr_idx]\n",
    "            y_train_pre = y.iloc[tr_idx]\n",
    "    \n",
    "            dtrain_pre = lgb.Dataset(X_train_pre, label=y_train_pre)\n",
    "    \n",
    "            # valid „Éá„Éº„Çø„Çí‰Ωø„Çè„Åö„Å´Â≠¶Áøí\n",
    "            pre_model = lgb.train(\n",
    "                pre_params,\n",
    "                dtrain_pre,\n",
    "            )\n",
    "    \n",
    "            # ÂØÑ‰∏éÂ∫¶„Åå 0 „Çà„ÇäÂ§ß„Åç„ÅÑÁâπÂæ¥Èáè„ÇíÂèñ„ÇäÂá∫„Åô\n",
    "            feature_importance = pre_model.feature_importance()\n",
    "            print(np.sum(feature_importance == 0) / len(feature_importance))\n",
    "            \n",
    "            feature_name = pre_model.feature_name()\n",
    "            use_features = [feature_name[idx] for idx in range(len(feature_name)) if feature_importance[idx] > 0]\n",
    "        else:\n",
    "            use_features = features\n",
    "        print(len(use_features))        \n",
    "\n",
    "        # ÁâπÂæ¥ÈáèÈÅ∏Êäû„Åó„Å¶ valid „Éá„Éº„Çø„Å®„Å®„ÇÇ„Å´Â≠¶Áøí\n",
    "        X_train, X_val = X.iloc[tr_idx][use_features], X.iloc[val_idx][use_features]\n",
    "        y_train, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "\n",
    "        if config[\"augumented_gmm\"]:\n",
    "            X_train, y_train = add_augumented_gmm(X_train, y_train)    \n",
    "        \n",
    "        dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "        dval = lgb.Dataset(X_val, label=y_val, reference=dtrain)\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            valid_sets=[dtrain, dval],\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=50),\n",
    "                lgb.log_evaluation(200)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        save_lgb_model(model, str(model_output_path / f\"model_{target_col}_{fold}.txt\"))\n",
    "\n",
    "        pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        oof[val_idx] = pred\n",
    "\n",
    "        mse = mean_squared_error(y_val, pred)\n",
    "        mae = mean_absolute_error(y_val, pred)\n",
    "        loss_table[\"fold\"] = fold\n",
    "        loss_table[\"target\"] = target_col\n",
    "        loss_table[\"mae\"] = mae\n",
    "        loss_table[\"mse\"] = mse\n",
    "\n",
    "        loss_tables.append(loss_table)\n",
    "        models.append(model)\n",
    "\n",
    "    score_mse = mean_squared_error(y, oof)\n",
    "    score_mae = mean_absolute_error(y, oof)\n",
    "    print(f\"RMSE for {target_col}: {score_mse:.4f}\")\n",
    "    print(f\"MAE for {target_col}: {score_mae:.4f}\")\n",
    "    mae_dict[target_col] = score_mae\n",
    "\n",
    "    for loss_table in loss_tables:\n",
    "        loss_table_wandb.add_data(exp, model_name, loss_table[\"fold\"], loss_table[\"target\"], loss_table[\"mae\"], loss_table[\"mse\"])\n",
    "    all_loss_tables += loss_tables\n",
    "\n",
    "    oof_df = pd.DataFrame({\n",
    "        \"id\": df_train[\"id\"].values,\n",
    "        target_col: oof\n",
    "    })\n",
    "    oof_dfs.append(oof_df)   \n",
    "\n",
    "    all_models[target_col] = models\n",
    "\n",
    "wandb.log({\"fold_target_losses\": loss_table_wandb})\n",
    "# target ÊØé„ÅÆ Âπ≥Âùá mae „ÇíË®òÈå≤\n",
    "for target in targets:\n",
    "    key_name = f\"{target}_mean_mae\"\n",
    "    mae_values = mae_dict[target]\n",
    "    # mae_values = [d[\"mae\"] for d in all_loss_tables if d[\"target\"] == target]\n",
    "    wandb.log({key_name: np.mean(mae_values)})\n",
    "\n",
    " \n",
    "# CV Ë®àÁÆó\n",
    "oof_df = pd.DataFrame()\n",
    "oof_df[\"id\"] = train[\"id\"]\n",
    "for i_oof in oof_dfs:\n",
    "    oof_df = oof_df.merge(i_oof, on=\"id\", how=\"left\")\n",
    "oof_df.to_csv(output_path / \"oof.csv\", index=False)\n",
    "\n",
    "solution = train[[\"id\"] + targets].copy()\n",
    "solution = solution.fillna(NULL_FOR_SUBMISSION)\n",
    "oof_df = oof_df.fillna(NULL_FOR_SUBMISSION)\n",
    "\n",
    "# Ë©ï‰æ°\n",
    "final_score = score(\n",
    "    solution=solution,\n",
    "    submission=oof_df,\n",
    ")\n",
    "print(f\"\\nüìä Final OOF Score (wMAE): {final_score:.6f}\")\n",
    "wandb.log({\"wMAE\": final_score})\n",
    "\n",
    "# target ÊØé„ÅÆ best_iteration „Çí‰øùÂ≠ò„Åô„Çã„ÄÇ‰øùÂ≠ò„Åó„Åü„É¢„Éá„É´„Å´„ÅØË®òÈå≤„Åï„Çå„Å¶„Å™„Åã„Å£„Åü\n",
    "best_iterations = {}\n",
    "for target in targets:\n",
    "    target_best_iterations = [model.best_iteration for model in all_models[target]]\n",
    "    best_iterations[target] = target_best_iterations\n",
    "print(best_iterations)\n",
    "\n",
    "with open(output_path / \"best_iterations.json\", \"w\") as f:\n",
    "    json.dump(best_iterations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28666d6-13fb-41f1-8dec-41389ad92910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opp2025_myenv",
   "language": "python",
   "name": "opp2025_myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
