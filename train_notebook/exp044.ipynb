{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "634a0b10-991b-4d14-b39c-6507c6bcb418",
   "metadata": {},
   "source": [
    "- -> exp043\n",
    "- morgan fingerprint „ÅÆÊ¨°ÂÖÉ„ÇíÂúßÁ∏Æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa7a2c22-eb3e-479e-8f1f-9f9b50a176ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autotime\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7174264-b9fd-41b5-91fe-f5174dd30852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "is_kaggle_notebook = os.path.exists(\"/kaggle/input\")\n",
    "\n",
    "# ÂøÖË¶Å„Éë„ÉÉ„Ç±„Éº„Ç∏„Çí„Ç§„É≥„Çπ„Éà„Éº„É´\n",
    "if is_kaggle_notebook:\n",
    "    !pip install /kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl\n",
    "    !pip install /kaggle/input/torch-geometric-2-6-1/torch_geometric-2.6.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3f929c2-afe2-4fcb-986b-6f50075faa7a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import wandb\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from rdkit import rdBase\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GroupKFold, KFold\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy import sparse\n",
    "\n",
    "rdBase.DisableLog(\"rdApp.warning\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de6f94aa-f4e5-4b14-8bad-f9f73cd60375",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "pr_number = 1\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ccadd16-5880-496e-a632-4d5940b2266c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "if is_kaggle_notebook:\n",
    "    module_path = f\"/kaggle/input/myproject-pr-{pr_number:04}\"\n",
    "    !mkdir src\n",
    "    !cp -r $module_path/* src/\n",
    "    src_path = \"./\"\n",
    "else:\n",
    "    src_path = \"../\"\n",
    "\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from src.data import load_data, add_descriptors, add_external_data, make_smile_canonical, add_maccs, add_augumented_gmm, add_graph_features, add_count_atoms\n",
    "from src.model import train_lgb_for_target, save_lgb_model\n",
    "from src.utils import NULL_FOR_SUBMISSION, generate_scaffold, score, add_scaffold_kfold, scaffold_cv_split, get_useless_cols\n",
    "from src.utils.upload_kaggle_dataset import (\n",
    "    create_kaggle_dataset_metadata,\n",
    "    upload_kaggle_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "915c44aa-01b8-4b84-a377-6cf8d5e9a31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir ../outputs/exp044\n",
    "# !cp ../outputs/exp043/train.csv ../outputs/exp044/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ef59d0f-f03f-4636-9839-c8cbc2b4cfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"exp044\"\n",
    "notes = \"morgan finger print „ÅÆÁâπÂæ¥Èáè„ÇíÂúßÁ∏Æ\"\n",
    "model_name = \"lgb\"\n",
    "\n",
    "config = {\n",
    "    \"debug\": debug,\n",
    "    \"n_splits\": 3,\n",
    "    \"num_epochs\": 1000,\n",
    "    \"batch_size\": 128,\n",
    "    \"drop_ratio\": 0.5,\n",
    "    \"force_update_train\": False,\n",
    "    \"augumented_gmm\": False,\n",
    "    \"is_complement\": True\n",
    "}\n",
    "\n",
    "dataset_title = f\"model-{exp}\"\n",
    "dataset_id = f\"koya346/{dataset_title}\"\n",
    "\n",
    "if is_kaggle_notebook:\n",
    "    config[\"debug\"] = False\n",
    "\n",
    "if config[\"debug\"]:\n",
    "    config[\"n_splits\"] = 2\n",
    "    config[\"num_epochs\"] = 10\n",
    "\n",
    "targets = [\"Tg\", \"FFV\", \"Tc\", \"Density\", \"Rg\"]\n",
    "\n",
    "# TODO: Â≠¶Áøí„Éë„É©„É°„Éº„ÇøÂÆöÁæ©\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"mae\",\n",
    "    \"verbosity\": -1,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"max_depth\": 7,\n",
    "    \"seed\": 42,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.6,\n",
    "    \"num_boost_round\": 20000,\n",
    "}\n",
    "\n",
    "config.update(params)\n",
    "pre_params = copy.deepcopy(params)\n",
    "pre_params[\"num_boost_round\"] = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16a10533-77cf-436d-8abf-a3ae32a17545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Density_mean_mae</td><td>‚ñÅ</td></tr><tr><td>FFV_mean_mae</td><td>‚ñÅ</td></tr><tr><td>Rg_mean_mae</td><td>‚ñÅ</td></tr><tr><td>Tc_mean_mae</td><td>‚ñÅ</td></tr><tr><td>Tg_mean_mae</td><td>‚ñÅ</td></tr><tr><td>wMAE</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Density_mean_mae</td><td>0.0654</td></tr><tr><td>FFV_mean_mae</td><td>0.00828</td></tr><tr><td>Notes</td><td>morgan finger print ...</td></tr><tr><td>Rg_mean_mae</td><td>2.21596</td></tr><tr><td>Tc_mean_mae</td><td>0.03977</td></tr><tr><td>Tg_mean_mae</td><td>34.6148</td></tr><tr><td>wMAE</td><td>0.0702</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exp044_lgb</strong> at: <a href='https://wandb.ai/ko_ya346/opp2025/runs/hwem2e8t' target=\"_blank\">https://wandb.ai/ko_ya346/opp2025/runs/hwem2e8t</a><br> View project at: <a href='https://wandb.ai/ko_ya346/opp2025' target=\"_blank\">https://wandb.ai/ko_ya346/opp2025</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250824_144214-hwem2e8t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kouya-takahashi/kaggle/opp2025/notebook/wandb/run-20250824_144340-z15eq4ax</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ko_ya346/opp2025/runs/z15eq4ax' target=\"_blank\">exp044_lgb</a></strong> to <a href='https://wandb.ai/ko_ya346/opp2025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ko_ya346/opp2025' target=\"_blank\">https://wandb.ai/ko_ya346/opp2025</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ko_ya346/opp2025/runs/z15eq4ax' target=\"_blank\">https://wandb.ai/ko_ya346/opp2025/runs/z15eq4ax</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bit cols:  1114\n",
      "remove cols:  474\n",
      "838\n",
      "\n",
      "=== Training for target: Tg ===\n",
      "fold: 1\n",
      "0.5119331742243437\n",
      "409\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 33.973\tvalid_1's l1: 54.8497\n",
      "[400]\ttraining's l1: 25.5889\tvalid_1's l1: 44.9609\n",
      "[600]\ttraining's l1: 22.5282\tvalid_1's l1: 42.4655\n",
      "[800]\ttraining's l1: 20.6804\tvalid_1's l1: 40.9348\n",
      "[1000]\ttraining's l1: 19.1511\tvalid_1's l1: 39.8856\n",
      "[1200]\ttraining's l1: 17.8942\tvalid_1's l1: 39.4925\n",
      "Early stopping, best iteration is:\n",
      "[1219]\ttraining's l1: 17.7891\tvalid_1's l1: 39.4657\n",
      "fold: 2\n",
      "0.5107398568019093\n",
      "410\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 34.8635\tvalid_1's l1: 42.4119\n",
      "[400]\ttraining's l1: 25.6593\tvalid_1's l1: 36.3111\n",
      "[600]\ttraining's l1: 22.5819\tvalid_1's l1: 34.6892\n",
      "[800]\ttraining's l1: 20.7318\tvalid_1's l1: 33.9556\n",
      "[1000]\ttraining's l1: 19.1882\tvalid_1's l1: 33.4409\n",
      "[1200]\ttraining's l1: 17.9477\tvalid_1's l1: 33.1099\n",
      "[1400]\ttraining's l1: 16.8777\tvalid_1's l1: 32.9183\n",
      "[1600]\ttraining's l1: 15.93\tvalid_1's l1: 32.7849\n",
      "[1800]\ttraining's l1: 15.0435\tvalid_1's l1: 32.669\n",
      "[2000]\ttraining's l1: 14.3329\tvalid_1's l1: 32.5889\n",
      "[2200]\ttraining's l1: 13.6645\tvalid_1's l1: 32.536\n",
      "[2400]\ttraining's l1: 13.0541\tvalid_1's l1: 32.4824\n",
      "[2600]\ttraining's l1: 12.4903\tvalid_1's l1: 32.4118\n",
      "Early stopping, best iteration is:\n",
      "[2645]\ttraining's l1: 12.3766\tvalid_1's l1: 32.3984\n",
      "fold: 3\n",
      "0.5465393794749404\n",
      "380\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 36.2865\tvalid_1's l1: 37.26\n",
      "[400]\ttraining's l1: 26.9577\tvalid_1's l1: 31.6589\n",
      "[600]\ttraining's l1: 23.6118\tvalid_1's l1: 30.4225\n",
      "[800]\ttraining's l1: 21.6083\tvalid_1's l1: 29.8793\n",
      "[1000]\ttraining's l1: 20.1104\tvalid_1's l1: 29.5782\n",
      "[1200]\ttraining's l1: 18.8516\tvalid_1's l1: 29.4027\n",
      "[1400]\ttraining's l1: 17.8156\tvalid_1's l1: 29.2529\n",
      "[1600]\ttraining's l1: 16.9045\tvalid_1's l1: 29.1341\n",
      "[1800]\ttraining's l1: 16.0834\tvalid_1's l1: 29.0468\n",
      "[2000]\ttraining's l1: 15.3667\tvalid_1's l1: 28.9862\n",
      "[2200]\ttraining's l1: 14.6495\tvalid_1's l1: 28.9369\n",
      "[2400]\ttraining's l1: 14.0155\tvalid_1's l1: 28.8766\n",
      "Early stopping, best iteration is:\n",
      "[2468]\ttraining's l1: 13.8124\tvalid_1's l1: 28.8474\n",
      "RMSE for Tg: 2217.4892\n",
      "MAE for Tg: 33.6294\n",
      "\n",
      "=== Training for target: FFV ===\n",
      "fold: 1\n",
      "0.5739856801909308\n",
      "357\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 0.00820198\tvalid_1's l1: 0.0127182\n",
      "[400]\ttraining's l1: 0.00588263\tvalid_1's l1: 0.0112723\n",
      "[600]\ttraining's l1: 0.00513826\tvalid_1's l1: 0.0109281\n",
      "[800]\ttraining's l1: 0.00470598\tvalid_1's l1: 0.0107344\n",
      "[1000]\ttraining's l1: 0.00441059\tvalid_1's l1: 0.0106644\n",
      "[1200]\ttraining's l1: 0.00417105\tvalid_1's l1: 0.0105894\n",
      "Early stopping, best iteration is:\n",
      "[1345]\ttraining's l1: 0.00401471\tvalid_1's l1: 0.0105212\n",
      "fold: 2\n",
      "0.5441527446300716\n",
      "382\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 0.0088936\tvalid_1's l1: 0.0106398\n",
      "[400]\ttraining's l1: 0.0064571\tvalid_1's l1: 0.00900947\n",
      "[600]\ttraining's l1: 0.00556272\tvalid_1's l1: 0.00850327\n",
      "[800]\ttraining's l1: 0.0049877\tvalid_1's l1: 0.00823066\n",
      "[1000]\ttraining's l1: 0.00455109\tvalid_1's l1: 0.00805816\n",
      "[1200]\ttraining's l1: 0.00422321\tvalid_1's l1: 0.00793016\n",
      "[1400]\ttraining's l1: 0.00394762\tvalid_1's l1: 0.0078356\n",
      "[1600]\ttraining's l1: 0.00372384\tvalid_1's l1: 0.00775516\n",
      "[1800]\ttraining's l1: 0.00354595\tvalid_1's l1: 0.00769369\n",
      "[2000]\ttraining's l1: 0.0033793\tvalid_1's l1: 0.00763995\n",
      "[2200]\ttraining's l1: 0.0032411\tvalid_1's l1: 0.00760341\n",
      "[2400]\ttraining's l1: 0.00312181\tvalid_1's l1: 0.00756723\n",
      "[2600]\ttraining's l1: 0.00300876\tvalid_1's l1: 0.00753117\n",
      "[2800]\ttraining's l1: 0.00291276\tvalid_1's l1: 0.00750606\n",
      "[3000]\ttraining's l1: 0.00282193\tvalid_1's l1: 0.00748495\n",
      "[3200]\ttraining's l1: 0.00273838\tvalid_1's l1: 0.00746402\n",
      "[3400]\ttraining's l1: 0.00265291\tvalid_1's l1: 0.00744328\n",
      "[3600]\ttraining's l1: 0.00256335\tvalid_1's l1: 0.00742297\n",
      "[3800]\ttraining's l1: 0.00247858\tvalid_1's l1: 0.00740892\n",
      "[4000]\ttraining's l1: 0.00237842\tvalid_1's l1: 0.00739092\n",
      "[4200]\ttraining's l1: 0.00229258\tvalid_1's l1: 0.00737484\n",
      "[4400]\ttraining's l1: 0.00219772\tvalid_1's l1: 0.00735888\n",
      "[4600]\ttraining's l1: 0.00211505\tvalid_1's l1: 0.00734292\n",
      "[4800]\ttraining's l1: 0.00203849\tvalid_1's l1: 0.00733329\n",
      "[5000]\ttraining's l1: 0.00196793\tvalid_1's l1: 0.00732496\n",
      "[5200]\ttraining's l1: 0.00190064\tvalid_1's l1: 0.00731539\n",
      "[5400]\ttraining's l1: 0.00183916\tvalid_1's l1: 0.00730656\n",
      "[5600]\ttraining's l1: 0.00177892\tvalid_1's l1: 0.0072985\n",
      "[5800]\ttraining's l1: 0.00172498\tvalid_1's l1: 0.00729333\n",
      "[6000]\ttraining's l1: 0.00166967\tvalid_1's l1: 0.00728942\n",
      "Early stopping, best iteration is:\n",
      "[6019]\ttraining's l1: 0.00166362\tvalid_1's l1: 0.00728862\n",
      "fold: 3\n",
      "0.568019093078759\n",
      "362\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 0.0092733\tvalid_1's l1: 0.00967211\n",
      "[400]\ttraining's l1: 0.00669165\tvalid_1's l1: 0.00792455\n",
      "[600]\ttraining's l1: 0.00570981\tvalid_1's l1: 0.00730758\n",
      "[800]\ttraining's l1: 0.00514215\tvalid_1's l1: 0.00702466\n",
      "[1000]\ttraining's l1: 0.0047195\tvalid_1's l1: 0.00681887\n",
      "[1200]\ttraining's l1: 0.00438728\tvalid_1's l1: 0.00668106\n",
      "[1400]\ttraining's l1: 0.00413471\tvalid_1's l1: 0.0065712\n",
      "[1600]\ttraining's l1: 0.00392723\tvalid_1's l1: 0.00649571\n",
      "[1800]\ttraining's l1: 0.00373068\tvalid_1's l1: 0.00642137\n",
      "[2000]\ttraining's l1: 0.00355008\tvalid_1's l1: 0.00635474\n",
      "[2200]\ttraining's l1: 0.00339861\tvalid_1's l1: 0.00630555\n",
      "[2400]\ttraining's l1: 0.00324645\tvalid_1's l1: 0.00625705\n",
      "[2600]\ttraining's l1: 0.00309649\tvalid_1's l1: 0.00621381\n",
      "[2800]\ttraining's l1: 0.00297163\tvalid_1's l1: 0.00617854\n",
      "[3000]\ttraining's l1: 0.00286362\tvalid_1's l1: 0.00614893\n",
      "[3200]\ttraining's l1: 0.00275878\tvalid_1's l1: 0.00612761\n",
      "[3400]\ttraining's l1: 0.00265985\tvalid_1's l1: 0.0061057\n",
      "[3600]\ttraining's l1: 0.0025689\tvalid_1's l1: 0.00608885\n",
      "[3800]\ttraining's l1: 0.00246357\tvalid_1's l1: 0.00606495\n",
      "[4000]\ttraining's l1: 0.00237039\tvalid_1's l1: 0.00604532\n",
      "[4200]\ttraining's l1: 0.0022869\tvalid_1's l1: 0.00603118\n",
      "[4400]\ttraining's l1: 0.00221073\tvalid_1's l1: 0.00601984\n",
      "[4600]\ttraining's l1: 0.0021368\tvalid_1's l1: 0.0060104\n",
      "[4800]\ttraining's l1: 0.00206455\tvalid_1's l1: 0.00599889\n",
      "[5000]\ttraining's l1: 0.00199479\tvalid_1's l1: 0.005992\n",
      "Early stopping, best iteration is:\n",
      "[5085]\ttraining's l1: 0.00196527\tvalid_1's l1: 0.005988\n",
      "RMSE for FFV: 0.0002\n",
      "MAE for FFV: 0.0078\n",
      "\n",
      "=== Training for target: Tc ===\n",
      "fold: 1\n",
      "0.801909307875895\n",
      "166\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 0.0293716\tvalid_1's l1: 0.0368312\n",
      "[400]\ttraining's l1: 0.0234752\tvalid_1's l1: 0.0342318\n",
      "[600]\ttraining's l1: 0.0207831\tvalid_1's l1: 0.0339813\n",
      "Early stopping, best iteration is:\n",
      "[586]\ttraining's l1: 0.0209398\tvalid_1's l1: 0.033948\n",
      "fold: 2\n",
      "0.7899761336515513\n",
      "176\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 0.025899\tvalid_1's l1: 0.03926\n",
      "[400]\ttraining's l1: 0.0202155\tvalid_1's l1: 0.0338986\n",
      "[600]\ttraining's l1: 0.0181567\tvalid_1's l1: 0.0323968\n",
      "Early stopping, best iteration is:\n",
      "[654]\ttraining's l1: 0.0177895\tvalid_1's l1: 0.0322708\n",
      "fold: 3\n",
      "0.7875894988066826\n",
      "178\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 0.0222722\tvalid_1's l1: 0.058633\n",
      "[400]\ttraining's l1: 0.0161045\tvalid_1's l1: 0.0565047\n",
      "Early stopping, best iteration is:\n",
      "[472]\ttraining's l1: 0.0153238\tvalid_1's l1: 0.0562314\n",
      "RMSE for Tc: 0.0050\n",
      "MAE for Tc: 0.0378\n",
      "\n",
      "=== Training for target: Density ===\n",
      "fold: 1\n",
      "0.8556085918854416\n",
      "121\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 0.0335679\tvalid_1's l1: 0.077519\n",
      "[400]\ttraining's l1: 0.0227966\tvalid_1's l1: 0.0692613\n",
      "[600]\ttraining's l1: 0.0183244\tvalid_1's l1: 0.0670983\n",
      "[800]\ttraining's l1: 0.0154302\tvalid_1's l1: 0.0667993\n",
      "Early stopping, best iteration is:\n",
      "[759]\ttraining's l1: 0.0159885\tvalid_1's l1: 0.0665188\n",
      "fold: 2\n",
      "0.8329355608591885\n",
      "140\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 0.0312401\tvalid_1's l1: 0.051003\n",
      "[400]\ttraining's l1: 0.0207984\tvalid_1's l1: 0.0445915\n",
      "[600]\ttraining's l1: 0.0172626\tvalid_1's l1: 0.0427392\n",
      "Early stopping, best iteration is:\n",
      "[642]\ttraining's l1: 0.0167409\tvalid_1's l1: 0.042637\n",
      "fold: 3\n",
      "0.8448687350835322\n",
      "130\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 0.0290121\tvalid_1's l1: 0.0575457\n",
      "Early stopping, best iteration is:\n",
      "[227]\ttraining's l1: 0.0260459\tvalid_1's l1: 0.0570895\n",
      "RMSE for Density: 0.0111\n",
      "MAE for Density: 0.0587\n",
      "\n",
      "=== Training for target: Rg ===\n",
      "fold: 1\n",
      "0.8365155131264916\n",
      "137\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 1.45501\tvalid_1's l1: 2.31922\n",
      "[400]\ttraining's l1: 1.03032\tvalid_1's l1: 2.02653\n",
      "[600]\ttraining's l1: 0.809406\tvalid_1's l1: 1.97952\n",
      "Early stopping, best iteration is:\n",
      "[695]\ttraining's l1: 0.734508\tvalid_1's l1: 1.97419\n",
      "fold: 2\n",
      "0.8174224343675418\n",
      "153\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 1.41094\tvalid_1's l1: 1.93474\n",
      "[400]\ttraining's l1: 1.01282\tvalid_1's l1: 1.73106\n",
      "Early stopping, best iteration is:\n",
      "[534]\ttraining's l1: 0.922979\tvalid_1's l1: 1.7152\n",
      "fold: 3\n",
      "0.8126491646778043\n",
      "157\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\ttraining's l1: 1.26987\tvalid_1's l1: 2.82363\n",
      "[400]\ttraining's l1: 0.931061\tvalid_1's l1: 2.57685\n",
      "[600]\ttraining's l1: 0.81893\tvalid_1's l1: 2.55391\n",
      "[800]\ttraining's l1: 0.725427\tvalid_1's l1: 2.53731\n",
      "Early stopping, best iteration is:\n",
      "[752]\ttraining's l1: 0.744198\tvalid_1's l1: 2.53617\n",
      "RMSE for Rg: 8.4904\n",
      "MAE for Rg: 2.0159\n",
      "\n",
      "üìä Final OOF Score (wMAE): 0.064793\n",
      "{'Tg': [1219, 2645, 2468], 'FFV': [1345, 6019, 5085], 'Tc': [586, 654, 472], 'Density': [759, 642, 227], 'Rg': [695, 534, 752]}\n"
     ]
    }
   ],
   "source": [
    "wandb_name = f\"{exp}_{model_name}\" if not config[\"debug\"] else f\"{exp}_{model_name}_debug\"\n",
    "wandb.init(project=\"opp2025\", name=wandb_name, config=config)\n",
    "wandb.log({\"Notes\": notes})\n",
    "\n",
    "# ---------------------------\n",
    "# „É°„Ç§„É≥Âá¶ÁêÜ\n",
    "# ---------------------------\n",
    "if config[\"debug\"]:\n",
    "    output_path = Path(\"/home/kouya-takahashi/kaggle/opp2025/outputs\") / exp / \"debug\"\n",
    "else:\n",
    "    output_path = Path(\"/home/kouya-takahashi/kaggle/opp2025/outputs\") / exp\n",
    "\n",
    "model_output_path = output_path / \"model_cv\"\n",
    "if not os.path.exists(model_output_path):\n",
    "    os.makedirs(model_output_path)\n",
    "\n",
    "if is_kaggle_notebook:\n",
    "    # kaggle notebook\n",
    "    data_dir = Path(\"/kaggle/input\")\n",
    "else:\n",
    "    # local\n",
    "    data_dir = Path(\"/home/kouya-takahashi/kaggle/opp2025/data/raw\")\n",
    "\n",
    "# Â≠¶Áøí„Éá„Éº„ÇøÁî®ÊÑè\n",
    "\n",
    "if os.path.exists(output_path / \"train.csv\") and not config[\"force_update_train\"]:\n",
    "    train = pd.read_csv(output_path / \"train.csv\")\n",
    "else:\n",
    "    train, _ = load_data(data_dir)\n",
    "    train[\"SMILES\"] = train[\"SMILES\"].apply(make_smile_canonical)\n",
    "\n",
    "    if config[\"debug\"]:\n",
    "        # ÂêÑ„Çø„Éº„Ç≤„ÉÉ„Éà„ÅåÊ¨†Êêç„Åó„Å¶„ÅÑ„Å™„ÅÑ„Éá„Éº„Çø„Çí30 ‰ª∂„Åö„Å§Âèñ„ÇäÂá∫„Åô\n",
    "        tmp_dfs = []\n",
    "        for target in targets:\n",
    "            cond = train[target].notnull()\n",
    "            tmp_dfs.append(train[cond].iloc[:30])\n",
    "        train = pd.concat(tmp_dfs).reset_index(drop=True)\n",
    "    else:\n",
    "        print(train.shape)\n",
    "        external_data_dict = [\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"neurips-open-polymer-prediction-2025/train_supplement/dataset3.csv\",\n",
    "                \"col\": \"Tg\",\n",
    "            },\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"neurips-open-polymer-prediction-2025/train_supplement/dataset1.csv\",\n",
    "                \"col\": \"Tc\",\n",
    "                \"rename_d\": {\"TC_mean\": \"Tc\"},\n",
    "            },\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"neurips-open-polymer-prediction-2025/train_supplement/dataset4.csv\",\n",
    "                \"col\": \"FFV\",\n",
    "            },\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"tg-smiles-pid-polymer-class/TgSS_enriched_cleaned.csv\",\n",
    "                \"col\": \"Tg\",\n",
    "            },\n",
    "            # {\n",
    "            #     \"ex_path\": data_dir / \"smiles-extra-data/data_dnst1.xlsx\",\n",
    "            #     \"col\": \"Density\",\n",
    "            #     \"rename_d\": {\"density(g/cm3)\": \"Density\"}, \n",
    "            # },\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"smiles-extra-data/data_tg3.xlsx\",\n",
    "                \"col\": \"Tg\",\n",
    "                \"rename_d\": {\"Tg [K]\": \"Tg\"}, \n",
    "            },\n",
    "            {\n",
    "                \"ex_path\": data_dir / \"smiles-extra-data/JCIM_sup_bigsmiles.csv\",\n",
    "                \"col\": \"Tg\",\n",
    "                \"rename_d\": {\"Tg (C)\": \"Tg\"}, \n",
    "            },\n",
    "        ]\n",
    "        for d in external_data_dict:\n",
    "            print(f\"ex_path: {str(d['ex_path'])}\")\n",
    "            train = add_external_data(\n",
    "                df=train,\n",
    "                ex_path=d.get(\"ex_path\"),\n",
    "                col=d.get(\"col\"),\n",
    "                rename_d=d.get(\"rename_d\"),\n",
    "                is_complement=config[\"is_complement\"]\n",
    "            )\n",
    "            print(\"after train.shape: \", train.shape)\n",
    "\n",
    "    train = add_maccs(train)\n",
    "\n",
    "    # rdkit „ÅÆË®òËø∞Â≠ê, morgan finger print\n",
    "    train = add_descriptors(train, radius=2, fp_size=1024)\n",
    "\n",
    "    new_cols = []\n",
    "    seen = {}\n",
    "    for col in train.columns:\n",
    "        if col in seen:\n",
    "            seen[col] += 1\n",
    "            new_cols.append(f\"{col}_{seen[col]}\")\n",
    "        else:\n",
    "            seen[col] = 0\n",
    "            new_cols.append(col)\n",
    "    \n",
    "    train.columns = new_cols\n",
    "    \n",
    "    # id „ÅåÊ¨†Êêç„Åó„Å¶„ÅÑ„Çã -> ËøΩÂä†„Éá„Éº„Çø\n",
    "    train[\"is_external\"] = train[\"id\"].isnull()\n",
    "    \n",
    "    # „Ç∞„É©„ÉïÁâπÂæ¥Èáè\n",
    "    train = add_graph_features(train)\n",
    "    train = add_count_atoms(train)\n",
    "    \n",
    "    train[\"id\"] = np.arange(len(train))\n",
    "    features = train.drop(targets + [\"id\", \"SMILES\"], axis=1).columns\n",
    "    for col in features:\n",
    "        if train[col].dtype == \"object\":\n",
    "            train[col] = pd.to_numeric(train[col], errors=\"coerce\")\n",
    "    useless_cols = get_useless_cols(train.drop(targets + [\"id\", \"SMILES\"], axis=1))\n",
    "    \n",
    "    train = train.drop(useless_cols, axis=1)\n",
    "    \n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    train.to_csv(output_path / \"train.csv\", index=False)\n",
    "    print(\"Saved train.csv\")\n",
    "\n",
    "# ‰∏çË¶Å„Å™„Éì„ÉÉ„ÉàÂàó„ÇíÈô§Âéª\n",
    "bit_cols = []\n",
    "remove_cols = []\n",
    "\n",
    "for col in train.drop(targets + [\"id\", \"SMILES\", \"is_external\"], axis=1).columns:\n",
    "    if len(train[col].unique()) != 2:\n",
    "        continue\n",
    "    if np.all(train[col].unique() == np.array([0, 1])):\n",
    "        bit_cols.append(col)\n",
    "        p = train[col].mean()\n",
    "        if p > 0.01 and p < 0.99:\n",
    "            continue\n",
    "        remove_cols.append(col)\n",
    "print(\"bit cols: \", len(bit_cols))\n",
    "print(\"remove cols: \", len(remove_cols))\n",
    "\n",
    "train = train.drop(remove_cols, axis=1)\n",
    "\n",
    "# # „Éì„ÉÉ„ÉàÂàó„ÅÆ‰∫ãÂâçÂàà„ÇäËæº„Åø\n",
    "# bit_col_groups = [\n",
    "#     {\"name\": \"mfp\", \"n_components\": 128}, \n",
    "#     {\"name\": \"maccs\", \"n_components\": 32}\n",
    "# ]\n",
    "# for d in bit_col_groups:\n",
    "#     print(d)\n",
    "#     cols = [col for col in train.columns if d[\"name\"] in col]\n",
    "#     df = train[cols]\n",
    "#     print(len(cols))\n",
    "    \n",
    "#     X_bids = sparse.csr_matrix(df.values)\n",
    "#     svd = TruncatedSVD(n_components=d[\"n_components\"], random_state=42)\n",
    "#     X_svd = svd.fit_transform(X_bids)\n",
    "#     X_svd_df = pd.DataFrame(X_svd, columns=[f'{d[\"name\"]}_{idx}' for idx in range(d[\"n_components\"])])\n",
    "#     print(X_svd_df.shape)\n",
    "\n",
    "#     # ÂÖÉ„ÅÆÁ≥ªÂàó„ÇíËêΩ„Å®„Åô\n",
    "#     train = train.drop(cols, axis=1)\n",
    "#     # ÂúßÁ∏Æ„Åó„ÅüÁ≥ªÂàó„ÇíËøΩÂä†\n",
    "#     train = pd.concat([train, X_svd_df], axis=1)\n",
    "#     print(train.shape)\n",
    "\n",
    "# Ë®àÁÆóÊ∏à„ÅÆ fold „ÇíÁ™ÅÂêà\n",
    "folds = pd.read_csv(\"../data/preprocess/fold/folds.csv\")\n",
    "train = train.merge(folds[[\"SMILES\", \"fold\"]], how=\"left\", on=\"SMILES\")\n",
    "\n",
    "\n",
    "features = train.drop(targets + [\"id\", \"SMILES\", \"fold\"], axis=1).columns\n",
    "print(len(features))\n",
    "oof_dfs = []\n",
    "\n",
    "loss_table_wandb = wandb.Table([\"exp\", \"model_name\", \"fold\", \"target\", \"mae\", \"mse\"])\n",
    "all_loss_tables = []\n",
    "mae_dict = {}\n",
    "all_models = {}\n",
    "\n",
    "for idx, target_col in enumerate(targets):\n",
    "    loss_tables = []\n",
    "    print(f\"\\n=== Training for target: {target_col} ===\")\n",
    "\n",
    "    df_train = train[train[target_col].notnull()].reset_index(drop=True)\n",
    "    X = df_train[features]\n",
    "    y = df_train[target_col]\n",
    "    oof = np.zeros(len(X))\n",
    "    \n",
    "    models = []\n",
    "\n",
    "    for fold, tr_idx, val_idx in scaffold_cv_split(df_train, n_splits=config[\"n_splits\"]):\n",
    "        loss_table = {}\n",
    "        print(f\"fold: {fold + 1}\")\n",
    "        if target_col in targets and not config[\"debug\"]:\n",
    "            X_train_pre = X.iloc[tr_idx]\n",
    "            y_train_pre = y.iloc[tr_idx]\n",
    "    \n",
    "            dtrain_pre = lgb.Dataset(X_train_pre, label=y_train_pre)\n",
    "    \n",
    "            # valid „Éá„Éº„Çø„Çí‰Ωø„Çè„Åö„Å´Â≠¶Áøí\n",
    "            pre_model = lgb.train(\n",
    "                pre_params,\n",
    "                dtrain_pre,\n",
    "            )\n",
    "    \n",
    "            # ÂØÑ‰∏éÂ∫¶„Åå 0 „Çà„ÇäÂ§ß„Åç„ÅÑÁâπÂæ¥Èáè„ÇíÂèñ„ÇäÂá∫„Åô\n",
    "            feature_importance = pre_model.feature_importance()\n",
    "            print(np.sum(feature_importance == 0) / len(feature_importance))\n",
    "            \n",
    "            feature_name = pre_model.feature_name()\n",
    "            use_features = [feature_name[idx] for idx in range(len(feature_name)) if feature_importance[idx] > 0]\n",
    "        else:\n",
    "            use_features = features\n",
    "        print(len(use_features))        \n",
    "\n",
    "        # ÁâπÂæ¥ÈáèÈÅ∏Êäû„Åó„Å¶ valid „Éá„Éº„Çø„Å®„Å®„ÇÇ„Å´Â≠¶Áøí\n",
    "        X_train, X_val = X.iloc[tr_idx][use_features], X.iloc[val_idx][use_features]\n",
    "        y_train, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "\n",
    "        if config[\"augumented_gmm\"]:\n",
    "            X_train, y_train = add_augumented_gmm(X_train, y_train)    \n",
    "        \n",
    "        dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "        dval = lgb.Dataset(X_val, label=y_val, reference=dtrain)\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            valid_sets=[dtrain, dval],\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=50),\n",
    "                lgb.log_evaluation(200)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        save_lgb_model(model, str(model_output_path / f\"model_{target_col}_{fold}.txt\"))\n",
    "\n",
    "        pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        oof[val_idx] = pred\n",
    "\n",
    "        mse = mean_squared_error(y_val, pred)\n",
    "        mae = mean_absolute_error(y_val, pred)\n",
    "        loss_table[\"fold\"] = fold\n",
    "        loss_table[\"target\"] = target_col\n",
    "        loss_table[\"mae\"] = mae\n",
    "        loss_table[\"mse\"] = mse\n",
    "\n",
    "        loss_tables.append(loss_table)\n",
    "        models.append(model)\n",
    "\n",
    "    score_mse = mean_squared_error(y, oof)\n",
    "    score_mae = mean_absolute_error(y, oof)\n",
    "    print(f\"RMSE for {target_col}: {score_mse:.4f}\")\n",
    "    print(f\"MAE for {target_col}: {score_mae:.4f}\")\n",
    "    mae_dict[target_col] = score_mae\n",
    "\n",
    "    for loss_table in loss_tables:\n",
    "        loss_table_wandb.add_data(exp, model_name, loss_table[\"fold\"], loss_table[\"target\"], loss_table[\"mae\"], loss_table[\"mse\"])\n",
    "    all_loss_tables += loss_tables\n",
    "\n",
    "    oof_df = pd.DataFrame({\n",
    "        \"id\": df_train[\"id\"].values,\n",
    "        target_col: oof\n",
    "    })\n",
    "    oof_dfs.append(oof_df)   \n",
    "\n",
    "    all_models[target_col] = models\n",
    "\n",
    "wandb.log({\"fold_target_losses\": loss_table_wandb})\n",
    "# target ÊØé„ÅÆ Âπ≥Âùá mae „ÇíË®òÈå≤\n",
    "for target in targets:\n",
    "    key_name = f\"{target}_mean_mae\"\n",
    "    mae_values = mae_dict[target]\n",
    "    # mae_values = [d[\"mae\"] for d in all_loss_tables if d[\"target\"] == target]\n",
    "    wandb.log({key_name: np.mean(mae_values)})\n",
    "\n",
    " \n",
    "# CV Ë®àÁÆó\n",
    "oof_df = pd.DataFrame()\n",
    "oof_df[\"id\"] = train[\"id\"]\n",
    "for i_oof in oof_dfs:\n",
    "    oof_df = oof_df.merge(i_oof, on=\"id\", how=\"left\")\n",
    "oof_df.to_csv(output_path / \"oof.csv\", index=False)\n",
    "\n",
    "solution = train[[\"id\"] + targets].copy()\n",
    "solution = solution.fillna(NULL_FOR_SUBMISSION)\n",
    "oof_df = oof_df.fillna(NULL_FOR_SUBMISSION)\n",
    "\n",
    "# Ë©ï‰æ°\n",
    "final_score = score(\n",
    "    solution=solution,\n",
    "    submission=oof_df,\n",
    ")\n",
    "print(f\"\\nüìä Final OOF Score (wMAE): {final_score:.6f}\")\n",
    "wandb.log({\"wMAE\": final_score})\n",
    "\n",
    "# target ÊØé„ÅÆ best_iteration „Çí‰øùÂ≠ò„Åô„Çã„ÄÇ‰øùÂ≠ò„Åó„Åü„É¢„Éá„É´„Å´„ÅØË®òÈå≤„Åï„Çå„Å¶„Å™„Åã„Å£„Åü\n",
    "best_iterations = {}\n",
    "for target in targets:\n",
    "    target_best_iterations = [model.best_iteration for model in all_models[target]]\n",
    "    best_iterations[target] = target_best_iterations\n",
    "print(best_iterations)\n",
    "\n",
    "with open(output_path / \"best_iterations.json\", \"w\") as f:\n",
    "    json.dump(best_iterations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "96b28ac2-bcc7-4faa-a53c-06bfc9dbae0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10345, 1239)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../outputs/exp031/train.csv\").shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opp2025_myenv",
   "language": "python",
   "name": "opp2025_myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
